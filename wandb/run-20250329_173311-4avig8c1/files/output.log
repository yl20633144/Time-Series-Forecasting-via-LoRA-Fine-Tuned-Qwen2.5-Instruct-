Training:   0%|          | 0/700 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training: 100%|██████████| 700/700 [14:09<00:00,  1.21s/it, loss=0.492]
Step 50: loss = 0.5513
Step 100: loss = 0.6756
Step 150: loss = 0.6474
Step 200: loss = 0.7501
Step 250: loss = 0.7033
Step 300: loss = 0.5595
Step 350: loss = 0.5115
Step 400: loss = 0.5833
Step 450: loss = 0.5758
Step 500: loss = 0.5275
Step 550: loss = 0.5578
Step 600: loss = 0.4921
Step 650: loss = 0.5931
Step 700: loss = 0.4924
