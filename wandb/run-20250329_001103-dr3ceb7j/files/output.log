Training:   0%|          | 0/500 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training: 100%|██████████| 500/500 [10:11<00:00,  1.22s/it, loss=0.623]
Step 50: loss = 2.4104
Step 100: loss = 2.2182
Step 150: loss = 0.5789
Step 200: loss = 3.1371
Step 250: loss = 0.5547
Step 300: loss = 1.4835
Step 350: loss = 0.6835
Step 400: loss = 0.9311
Step 450: loss = 0.4831
Step 500: loss = 0.6226
