src.evaluation
==============

.. py:module:: src.evaluation


Attributes
----------

.. autoapisummary::

   src.evaluation.device


Functions
---------

.. autoapisummary::

   src.evaluation.split_context_target
   src.evaluation.decode_tokens_to_numbers
   src.evaluation.evaluation


Module Contents
---------------

.. py:data:: device

.. py:function:: split_context_target(token_ids: torch.Tensor, context_ratio: float = 0.8)

   Splits a 1D tensor of token IDs into context and target parts.

   :param token_ids: A 1D tensor of token IDs.
   :type token_ids: torch.Tensor
   :param context_ratio: Fraction of tokens to use as context.
   :type context_ratio: float

   :returns: (context_ids, target_ids) (torch.Tensor, torch.Tensor)


.. py:function:: decode_tokens_to_numbers(text: str)

   Decodes a LLMTIME-formatted string into a list of numeric values.
   Example format: "0.25,1.50;0.27,1.47;0.31,1.42"

   We split by semicolon to separate timesteps, then by comma for variables,
   and parse each as a float.

   :param text: The decoded text from the model's output.
   :type text: str

   :returns: A flat list of numeric values (prey, predator, prey, predator, ...).
   :rtype: List[float]


.. py:function:: evaluation(model, tokenizer, tokenized_data, context_ratio: float = 0.7)

   Evaluates the model in a fully autoregressive manner using model.generate.

   For each sequence:
     1. Split the sequence into context and target using split_context_target.
     2. Use model.generate (with output_scores=True and return_dict_in_generate=True)
        to generate all target tokens at once.
     3. Extract the per-token logits (scores) for each generated token and compute the
        cross-entropy loss against the ground truth token.
     4. Compute the average loss over the generated tokens and log the loss curve.
     5. Decode the generated tokens and the ground truth target tokens into numeric values,
        and compute the Mean Squared Error (MSE) for forecast evaluation.

   :param model: The Qwen2.5-Instruct model.
   :param tokenizer: The corresponding tokenizer.
   :param tokenized_data: List of 1D token ID tensors.
   :type tokenized_data: List[torch.Tensor]
   :param context_ratio: Fraction of tokens used as context.
   :type context_ratio: float

   :returns: The average cross-entropy loss and MSE over evaluated sequences.
   :rtype: Tuple[float, float]


